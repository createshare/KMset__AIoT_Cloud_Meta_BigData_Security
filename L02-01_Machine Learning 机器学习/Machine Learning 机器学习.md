# Machine Learning 机器学习

## 人工智能（Artificial Intelligence，AI）

人工智能（Artificial Intelligence，AI）是计算机科学的一个分支，它是一门多领域交叉学科，用于研究、开发模拟、延伸和扩展人的智能的理论、方法、技术及应用系统，涉及计算机科学、信息论、控制论、自动化、仿生学、生物学、心理学、数理逻辑、语言学、医学、哲学等多门学科。

## 人工智能与机器学习

实际上，人工智能和机器学习并没有直接的关系。只不过在目前的技术水平下，机器学习的方法被大量地应用于解决人工智能的问题而已。

也可以这样说，机器学习是人工智能的一种实现方式，也是最重要的实现方式。



## 机器学习相关的基本概念

与机器学习密切相关的基本概念有标签、特征、模型、分类、回归和聚类等。



### 标签

标签是对事物进行标记的一种符号。人类的学习具有目标引导性，需要各种方向性的指引信息，机器的学习也是一样，通过标签的引导，让智能机器清楚学习的结果。在机器学习中，标签是需要机器预测的事物，标签可以是小麦未来的价格、动物的品种等。

### 特征

机器学习的任务就是从事物中提取特征并利用特征进行特定的工作。

### 模型

模型是对特征的一种数学的总结。
在机器学习中，模型的生命周期分为以下两个阶段：

- 训练，是指创建或学习模型。也就是说，向模型展示有标签的数据，让模型逐渐学习特征与标签之间的关系。
- 推理，是指将训练后的模型应用于无标签数据。也就是说，使用经过训练的模型做出有用的预测。

### 回归与分类

人类常用回归与分类方法来学习和处理问题。机器的学习也是一样，需要用到分类和回归这两种方法。
分类是指有有限种可能的问题，预测的是一个离散的、明确的变量。例如，给出一张图片，去判断是T恤、是裤子、或者其他种类，这个类别是有限的。
回归，是指有无限种可能的问题，预测的是一个连续的、逼近的变量，比如房价的预测、明日气温的预测。

通常采用分辨输出变量的类型来区分分类和回归：

- 定量输出称为线性回归，或者说是连续变量预测。例如，预测明天的气温是多少摄氏度。
- 定性输出称为逻辑回归，即分类，或者说是离散变量预测。例如，预测明天是阴、是晴、还是雨。

### 聚类

人类学习会经常用到聚类分析方法，聚类的实质是归纳总结。聚类分析又称群分析，它是研究（样品或指标）分类问题的一种统计分析方法。
机器的学习也是一样，需要通过聚类方法来不断地对客观世界进行归纳总结。
将物理或抽象对象的集合分成由相似的对象组成的多个类的过程，称为聚类。
由聚类所生成的簇是一组数据对象的集合，同一个簇中的对象彼此相似，不同簇中的对象彼此相异。
聚类算法应用场景实例————基于用户位置信息的商业选址。



# 机器学习的分类

机器学习包括学习方法、学习任务、学习模型三个方面，可以按这三个方面进行分类。

![机器学习总框图](figures/机器学习总框图.jpg)

## 按学习方法类型分

按学习方法分，机器学习模型可以分为有监督学习、半监督学习、无监督学习、迁移学习、强化学习。

### 有监督学习

在深度学习和机器学习领域中，大多数成功用例都属于有监督学习。

当训练样本带有标签时是有监督学习。

有监督学习：用已知某种或某些特性的样本作为训练集，以建立一个数学模型（例如，模式识别中的判别模型、人工神经网络中的权重模型等），于用已建立的模型来预测未知样本。

有监督学习是从标签化训练数据中推断出函数的机器学习任务。

有监督学习的工作就是通过有标签的数据训练，构建一个模型，然后通过构建的模型，给新数据添加特定的标签。即有监督学习同时将数据样本和标签输入给模型，模型学习到数据和标签的映射关系，从而对新数据进行预测，主要有分类和回归两种应用。

有监督学习的常见例子：

- 分类问题：狗和猫的分类。
- 回归问题：预测股票价格、比赛成绩等。
- 图像分割：进行像素级分类。这些像素可以是汽车、行人、树、公共汽车等。
- 语音识别：OK Google、Alexa、Siri 等
- 语言翻译

常用的有监督学习的算法包括：

- 支持向量机（Support Vector Machine）
- 线性回归（Linear Regression），解决回归问题的常用算法
- 逻辑回归（Logistic Regression），用于分类问题的常用算法
- 朴素贝叶斯（Naive Bayes）
- 线性判别分析（Linear Discriminant Analysis）
- 决策树（Decision Tree）
- K-近邻（K-Nearest Neighbor）



### 无监督学习

训练样本全部为无标签时是无监督学习。

无监督学习中的模型所学习的数据都是无标签的，可以根据类别未知的训练样本解决模式识别中的各种问题。目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。

在此类学习任务中研究最多、应用最广的是 “聚类（Clustering）”，聚类的目的在于把相似的东西聚在一起。

例如，智能机器通过学习到图像数据所具备的特征，把它们归纳成一个类别，这是典型的 “无师自通” 过程。

在没有标签数据的情况时，可以通过可视化和压缩来帮助无监督学习技术理解数据，无监督机器学习算法可分为两类：

- 降维算法
  - 采用未标注的数据和高维的数据（具有很多变量的数据），是一种以较少维数表示数据的方法。
  - 降维算法可作为一种探索性的技术（因为人类很难迅速、直观地理解二维或三维以上的数据）或作为机器学习进程中的预处理步骤（降维算法可以帮助减少共线性和维数灾难）。
  - 降维算法还可以帮助我们更直观地明确分类算法和聚类算法的性能（降维算法可以将数据在二维或三维空间中进行绘制显示）。
  - 降维有助于减少维数，从而可视化高维数据，并找到任何隐藏的模式。
- 聚类算法
  - 采用未标注的数据，并学习数据中的聚类模式。
  - 聚类是一组观察数据的集合。
  - 聚类算法可以作为一种探索性的技术来帮助我们了解数据的结构，还可以作为聚类结构输入分类算法中。
  - 聚类有助于将所有相似的数据点组合在一起。

常用的无监督学习算法包括：

- 密度估计（Density Estimation）
- 异常检测（Anomaly Detection）
- 层次聚类
- EM 算法
- K-Means 算法（K 均值算法）
- DBSCAN 算法

无监督学习则是需要机器自行判断结果是否恰当，进而优化判别参数。比如生成式对抗网络（GAN）应用的就是无监督学习，它可以根据此前的学习结果，构造出全新的模式（全新的猫或狗），来拓展对象认识的边界。

### 半监督学习

训练样本部分有标签、部分无标签时是半监督学习。

机器的学习跟人一样，需要不断地交替进行有监督学习和无监督学习。

半监督学习就是先在有监督的环境下初步建好模型，再进行无监督学习，实现机器智能的不断迭代和更新完善。

即半监督学习就是先用带有标签的数据帮助计算机初步构建模型，然后让智能机器根据已有的模型去学习无标签的数据。

在大数据时代，因为有标签数据的收集和标记需要消耗大量的人力物力，而海量的非标签数据触手可及，故 “半监督学习” 将成为大数据时代的发展趋势。



### 强化学习

强化学习（Reinforcement Learning，RL）是机器学习的一个重要分支，强调如何基于环境而行动，以取得预期利益的最大化。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性的行为。

强化学习是机器学习研究和应用的前沿领域，算法将不断从经验中进行学习，并当它们做出正确的决策时加以奖励。

强化学习是与监督学习算法、无监督学习算法并列的第三类机器学习算法。强化学习可以创建占用国际象棋世界冠军的象棋机器人。

强化训练即强化学习是一种学习最优策略（Policy），可以让本体（Agent）在特定环境（Environment）中，根据当前状态（State）做出行动（Action），从而获得最大回报（Reward）。

强化学习和有监督学习最大的不同是，强化学习中，每次的决定没有对与错，而是希望获得最多的累计奖励。

强化学习不像监督学习那样，对于每一个样本，都有一个确定的标签与之对应，强化学习没有标签，只有一个时间延迟的奖励，而且实际中往往会牺牲当前的奖励来获取将来更大的奖励。从某种意义上看，强化学习被认为是具有延迟标记的监督学习。

在强化学习中，包含两种基本的元素：状态、动作。例如，在围棋中，一种落棋的局面就是一种状态，若能知道每种局面下的最优落子动作，那就攻无不克、战无不胜。

强化学习的主要算法包括：

- 通过价值选行为：Q-Learning、Sarsa、Deep Q Network
- 直接选行为：Policy Gradient
- 想象环境并从中学习：Model-Based RL
- 回合更新：基础版的 Policy Gradient、Monte-Carlo Learning
- 单步更新：Q-Learning、Sarsa、升级版 Policy Gradient



### 迁移学习

人类似乎有一种与生俱来的学习能力——类似推理（简称 类推）。俗语主的 “学会一种而一通百通”

迁移学习就是把已经训练好的模型参数迁移到新的模型上以帮助新模型的训练。

数据爆炸要求人工智能技术具有快速响应的能力，具体表现为要求机器学习能快速构建强泛化的模型。但大部分数据是没有标签，并且收集标签数据和从头开始构建一个模型都是代价高昂的，所以需要对模型和带有标签的数据进行重用。这种 “重用” 技术就是迁移。

在迁移学习中，已有的知识叫作源域，要学习的新知识叫目标域。源域和目标域不同但有一定关联，需要减小源域和目标域的分布差异，进行知识迁移，从而实现数据标定。

常用的概念：

- 域（Domain）：由数据特征和特征分布组成，是学习的主体
- 源域（Source Domain）：已有知识的域
- 目标域（Target Domain）：要进行学习的域
- 任务（Task）：由目标函数和学习结果组成，是学习的结果，可理解为分类器
- 迁移学习条件：指面向某一任务进行迁移学习的实施条件，包括任务、目标、实现学习的约束条件
  - 任务：给定源域和源域的任务、目标域和目标域的任务
  - 目标：利用源域和源域任务学习目标域预测函数 f
  - 约束条件：源域和目标域不同、源任务和目标任务不同
- 领域自适应（Domain Adaptation）：有标签的源域和无标签的目标域共享一致的类别和特征，但分布不同
- 源域和目标域的区别：相对于目标域，源域在数据分布、特征维度、以及模型输出方面变化条件有所不同，有效地利用源域中的知识可以对目标域更好地建模。另外，在目标域标定数据缺乏的情况下，迁移学习可以很好地利用相关领域的标定数据，完成数据的标定。
- 负迁移：如果源域和目标域之间的相似度不够，迁移结果并不会理想，出现所谓的负迁移情况。如何找到相似度尽可能高的源域和目标域，是整个迁移过程最重要的前提。



迁移学习可以根据不同的方式进行分类：

- 基于样本的迁移学习：通过对源域中标记样本的加权利用来完成知识迁移，例如相似的样本就给予高的权重。
- 基于特征的迁移学习：通过将源域和目标域特征变换到相同的空间（或者将其中之一映射到另一个空间中），并将源域和目标域的距离最小化来完成知识迁移。
- 基于模型的迁移学习：将源域和目标域的模型与样本结合起来调整模型的参数。
- 基于关系的迁移学习：通过源域中学习概念之间的关系，然后将其类比到目标域中，完成知识的迁移。



## 按任务类型分

按任务类型分，机器学习模型可以分为回归任务、分类任务、结构化学习任务。

### 回归任务

回归任务又叫预测任务，输出是一个不能枚举的数值。

回归算法采用标注的数据，并学习数据中可用于预测连续输出变量的模式。

### 分类任务

分类任务又分为二分类任务、多分类任务。

常见的二分类任务有垃圾邮件过滤。

常见的多分类任务有文档自动归类。

分类算法采用标注的数据（因为采用监督的学习方法），并学习数据中可用于预测分类输出变量的模型。

### 结构化学习任务

结构化学习任务的输出不再是一个固定长度的值，如图片语义分析，输出是图片的文字描述。

## 按模型类型分

从模型的角度分，机器学习模型可以分为线性模型和非线性模型。

### 线性模型

线性模型较为简单，但线性模型是非线性模型的基础，很多非线性模型都是在线性模型的基础上变换而来的。

### 非线性模型

非线性模型又可以分为传统机器学习模型、深度学习模型。

例如，支持向量机（SVM）、K-NN、决策树等都属于传统机器学习模型。



# 机器学习的模型

## 线性模型



## 核模型



## 层级模型







# 编程语言

两种最常用的数据科学语言：R 和 Python。一些先进的深度学习算法容易先通过 Python 来编程实现，然后再用 R 语言实现。

## Python

Python 提供了著名的 scikit-learn 程序包，其中内置了大量的机器学习算法。

Python 将许多机器层面上的细节隐藏，将其交给编译器处理，并凸显出对逻辑层面的编程思考。可以花更多的时间思考程序的逻辑，而不是具体的实现细节。

## R

R 语言专门针对数学和统计学的相关应用。使用 R 语言可以只关注数据。

R 语言增加了 caret 和 mlr 程序包，为大量的机器学习算法提供了接口，可以使用很少的代码执行极其复杂的机器学习任务。

R 语言有专门用于简化数据科学任务并使之易于人们阅读的现代工具，例 tidyverse 程序包中的工具来组织、整理、绘制数据。



# 机器学习框架

| 框架名称     | 接口语言                     | 开源？ |      |
| ------------ | ---------------------------- | ------ | ---- |
| TensorFlow   | C++、Java、Python、Go、C# 等 | 开源   |      |
| PaddlePaddle | C++、Python                  | 开源   |      |
| Caffe        | C++、MATLAB、Python          | 开源   |      |
| PyTorch      | C++、Python 等               | 开源   |      |
| MXNet        | C++、Python、R、MATLAB 等    | 开源   |      |


